{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abdcbac",
   "metadata": {},
   "source": [
    "# SVM testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180264ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import matplotlib.pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15297a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jee_main_score</th>\n",
       "      <th>school_board</th>\n",
       "      <th>class_12_percent</th>\n",
       "      <th>attempt_count</th>\n",
       "      <th>coaching_institute</th>\n",
       "      <th>daily_study_hours</th>\n",
       "      <th>family_income</th>\n",
       "      <th>parent_education</th>\n",
       "      <th>location_type</th>\n",
       "      <th>peer_pressure_level</th>\n",
       "      <th>mental_health_issues</th>\n",
       "      <th>admission_taken</th>\n",
       "      <th>dropout</th>\n",
       "      <th>Income vs Admission</th>\n",
       "      <th>PSxIA</th>\n",
       "      <th>peer_focused_mh</th>\n",
       "      <th>parental_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.95</td>\n",
       "      <td>1</td>\n",
       "      <td>70.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.06</td>\n",
       "      <td>0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.07</td>\n",
       "      <td>2</td>\n",
       "      <td>64.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.32</td>\n",
       "      <td>2</td>\n",
       "      <td>73.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.72</td>\n",
       "      <td>1</td>\n",
       "      <td>89.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.16</td>\n",
       "      <td>4</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jee_main_score  school_board  class_12_percent  attempt_count  \\\n",
       "0           78.95             1             70.09              1   \n",
       "1           70.06             0             78.00              1   \n",
       "2           81.07             2             64.36              1   \n",
       "3           93.32             2             73.21              1   \n",
       "4           68.72             1             89.02              1   \n",
       "\n",
       "   coaching_institute  daily_study_hours  family_income  parent_education  \\\n",
       "0                   0                5.4              0                 0   \n",
       "1                   0                5.5              1                 0   \n",
       "2                   0                7.0              0                 3   \n",
       "3                   0                2.1              0                 1   \n",
       "4                   0                6.3              1                 2   \n",
       "\n",
       "   location_type  peer_pressure_level  mental_health_issues  admission_taken  \\\n",
       "0              2                    0                     0                0   \n",
       "1              2                    0                     1                0   \n",
       "2              1                    1                     1                0   \n",
       "3              1                    1                     1                1   \n",
       "4              1                    2                     0                1   \n",
       "\n",
       "   dropout  Income vs Admission  PSxIA  peer_focused_mh  parental_support  \n",
       "0        1                    0   0.00                0              1.62  \n",
       "1        0                    1   1.65                1              1.65  \n",
       "2        1                    0   0.00                3              2.70  \n",
       "3        0                    3   2.49                3              0.83  \n",
       "4        0                    4   9.16                4              2.29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jee = pd.read_csv(\"../01_Data/03_final/JEE_Dropout_Final.csv\", delimiter=',')\n",
    "jee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8386c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jee.drop([\"admission_taken\",\"Income vs Admission\",\"PSxIA\",\"dropout\"], axis=1)\n",
    "Y = jee[\"dropout\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a895db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6424474187380497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87       793\n",
      "           1       0.53      0.81      0.64       207\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.74      0.81      0.76      1000\n",
      "weighted avg       0.86      0.81      0.83      1000\n",
      "\n",
      "Accuracy:  0.6678700361010831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.87       793\n",
      "           1       0.53      0.89      0.67       207\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.75      0.84      0.77      1000\n",
      "weighted avg       0.88      0.82      0.83      1000\n",
      "\n",
      "Accuracy:  0.6832740213523132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88       793\n",
      "           1       0.54      0.93      0.68       207\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.76      0.86      0.78      1000\n",
      "weighted avg       0.89      0.82      0.84      1000\n",
      "\n",
      "[0.79222421 0.77630341 0.77327292 0.80083012 0.79379923]\n",
      "\n",
      "0.7872859777849577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pipeline = Pipeline([\n",
    "    ('smote',SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf',C=2,probability=True))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote',SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='linear',C=2,probability=True))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(f1_score,average='macro')\n",
    "pipeline = Pipeline([\n",
    "    ('smote',SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rfc', SVC(probability=True,random_state=42))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "cv= StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline,X, Y, scoring=scorer, cv=cv)\n",
    "\n",
    "print(scores)\n",
    "print()\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d486dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6290322580645161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       793\n",
      "           1       0.54      0.75      0.63       207\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.73      0.79      0.75      1000\n",
      "weighted avg       0.85      0.82      0.83      1000\n",
      "\n",
      "[0.77640482 0.78466242 0.77204418 0.78890038 0.79462398]\n",
      "\n",
      "0.7833271574016921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(f1_score,average='macro')\n",
    "pipeline = Pipeline([\n",
    "    ('smote',SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rfc', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "cv= StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline,X, Y, scoring=scorer, cv=cv)\n",
    "\n",
    "print(scores)\n",
    "print()\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1e2464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:19<31:50, 19.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 5. Explain a subset of the test set (scaled in the same way)\u001b[39;00m\n\u001b[32m     18\u001b[39m X_test_scaled = pipeline.named_steps[\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m].transform(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m shap_values = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 6. Plot summary for positive class (class index 1)\u001b[39;00m\n\u001b[32m     22\u001b[39m shap.summary_plot(shap_values[\u001b[32m1\u001b[39m], X_test_scaled[:\u001b[32m100\u001b[39m], feature_names=X_train.columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_kernel.py:275\u001b[39m, in \u001b[36mKernelExplainer.shap_values\u001b[39m\u001b[34m(self, X, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index:\n\u001b[32m    274\u001b[39m     data = convert_to_instance_with_index(data, column_name, index_value[i : i + \u001b[32m1\u001b[39m], index_name)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m explanations.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mgc_collect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    277\u001b[39m     gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_kernel.py:479\u001b[39m, in \u001b[36mKernelExplainer.explain\u001b[39m\u001b[34m(self, incoming_instance, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:] *= weight_left / \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:].sum()\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[32m    482\u001b[39m phi = np.zeros((\u001b[38;5;28mself\u001b[39m.data.groups_size, \u001b[38;5;28mself\u001b[39m.D))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_kernel.py:624\u001b[39m, in \u001b[36mKernelExplainer.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index_ordered:\n\u001b[32m    623\u001b[39m         data = data.sort_index()\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m modelOut = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelOut, (pd.DataFrame, pd.Series)):\n\u001b[32m    626\u001b[39m     modelOut = modelOut.values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:873\u001b[39m, in \u001b[36mBaseSVC.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    867\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[32m    868\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    869\u001b[39m     )\n\u001b[32m    870\u001b[39m pred_proba = (\n\u001b[32m    871\u001b[39m     \u001b[38;5;28mself\u001b[39m._sparse_predict_proba \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dense_predict_proba\n\u001b[32m    872\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpred_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:913\u001b[39m, in \u001b[36mBaseSVC._dense_predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    910\u001b[39m     kernel = \u001b[33m\"\u001b[39m\u001b[33mprecomputed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    912\u001b[39m svm_type = LIBSVM_IMPL.index(\u001b[38;5;28mself\u001b[39m._impl)\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m pprob = \u001b[43mlibsvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43msvm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pprob\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Transform your training data through SMOTE + scaling\n",
    "X_res, y_res = pipeline.named_steps['smote'].fit_resample(X_train, y_train)\n",
    "X_res_scaled = pipeline.named_steps['scaler'].fit_transform(X_res)\n",
    "\n",
    "# 2. Get the trained SVM model\n",
    "svm_model = pipeline.named_steps['svm']\n",
    "\n",
    "# 3. Select a small background dataset for SHAP speed\n",
    "background = shap.sample(X_res_scaled, 50, random_state=42)\n",
    "\n",
    "# 4. Create the SHAP explainer using predict_proba\n",
    "explainer = shap.KernelExplainer(svm_model.predict_proba, background)\n",
    "\n",
    "# 5. Explain a subset of the test set (scaled in the same way)\n",
    "X_test_scaled = pipeline.named_steps['scaler'].transform(X_test)\n",
    "shap_values = explainer.shap_values(X_test_scaled[:100])\n",
    "\n",
    "# 6. Plot summary for positive class (class index 1)\n",
    "shap.summary_plot(shap_values[1], X_test_scaled[:100], feature_names=X_train.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26b8b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.81       804\n",
      "           1       0.42      0.90      0.57       196\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.69      0.80      0.69      1000\n",
      "weighted avg       0.86      0.74      0.76      1000\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The passed model is not callable and cannot be analyzed directly with the given masker! Model: SVC(probability=True, random_state=42)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m X_sample = X_train_res.sample(\u001b[32m200\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Use the universal fast explainer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m explainer = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m shap_values = explainer(X_sample)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Summary plot\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Chr24\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\shap\\explainers\\_explainer.py:206\u001b[39m, in \u001b[36mExplainer.__init__\u001b[39m\u001b[34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m             algorithm = \u001b[33m\"\u001b[39m\u001b[33mpermutation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# if we get here then we don't know how to handle what was given to us\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    207\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe passed model is not callable and cannot be analyzed directly with the given masker! Model: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m             + \u001b[38;5;28mstr\u001b[39m(model)\n\u001b[32m    209\u001b[39m         )\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# build the right subclass\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m algorithm == \u001b[33m\"\u001b[39m\u001b[33mexact\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: The passed model is not callable and cannot be analyzed directly with the given masker! Model: SVC(probability=True, random_state=42)"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Assuming you already have df with target column 'target'\n",
    "# Train-test split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train SVM\n",
    "model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "# ---- SHAP PART ----\n",
    "# Take a small sample to speed things up\n",
    "X_sample = X_train_res.sample(200, random_state=42)\n",
    "\n",
    "# Use the universal fast explainer\n",
    "explainer = shap.Explainer(model, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=X.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
